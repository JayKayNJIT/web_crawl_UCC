# web_crawl_UCC
This script provides a sample algorithm on how to crawl a database from employment opportunity website (UCC in this case), and download the data (salary, organization size, location, date posted, benefits etc) and then rank the opportunities according to the organization size. Since the website (https://oppsearch.ucc.org/web/fastsearch.aspx) is blocking crawler from overloading the server, various tricks are being deployed in the script i.e. different headers and visiting random webpages on the website before making next attempt. Script will produce 3 Excel files: export_dataframe3.xlsx, export_dataframe3_missed.xlsx, export_dataframe3_missed2.xlsx. First file will containing the payload result, second file will contain the job IDs that were missed in the first attempt and third file will contain the IDs that were missed from 2nd attempt (###################### covering the missed values starts ######################). Script will keep bouncing between 2nd and 3rd file unless all the IDs are moved from from 2nd file to the first(payload) file. Please contact me at jatin.kashyap@njit.edu if you want the script to be modified to your specific project needs.
